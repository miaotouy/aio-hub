/**
 * èŠå¤©ä¸Šä¸‹æ–‡æ„å»º Composable
 * è´Ÿè´£æ„å»ºå‘é€ç»™ LLM çš„æœ€ç»ˆæ¶ˆæ¯åˆ—è¡¨
 */

import type { ChatSession, ChatMessageNode, ContextPostProcessRule } from "../types";
import type { LlmMessageContent } from "@/llm-apis/common";
import type { ModelCapabilities } from "@/types/llm-profiles";
import { createModuleLogger } from "@/utils/logger";
import { tokenCalculatorService } from "@/tools/token-calculator/tokenCalculator.registry";
import { useChatAssetProcessor } from "./useChatAssetProcessor";
import { useMacroProcessor } from "./useMacroProcessor";
import { useAgentStore } from "../agentStore";
import type { ProcessableMessage } from "./useMessageProcessor";

const logger = createModuleLogger("llm-chat/context-builder");

/**
 * LLM ä¸Šä¸‹æ–‡æ„å»ºç»“æœ
 * ç°åœ¨è¿”å›ç»Ÿä¸€çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå¯åŒ…å« system, user, assistant è§’è‰²
 */
interface LlmContextData {
  messages: Array<{
    role: "system" | "user" | "assistant";
    content: string | LlmMessageContent[];
  }>;
}

/**
 * ä¸Šä¸‹æ–‡é¢„è§ˆåˆ†æç»“æœ
 */
export interface ContextPreviewData {
  /** ç³»ç»Ÿæç¤ºéƒ¨åˆ† */
  systemPrompt?: {
    content: string;
    charCount: number;
    tokenCount?: number;
    source: "agent_preset";
  };
  /** é¢„è®¾æ¶ˆæ¯éƒ¨åˆ† */
  presetMessages: Array<{
    role: "user" | "assistant";
    content: string;
    charCount: number;
    tokenCount?: number;
    source: "agent_preset";
    index: number;
  }>;
  /** ä¼šè¯å†å²éƒ¨åˆ† */
  chatHistory: Array<{
    role: "user" | "assistant";
    content: string;
    charCount: number;
    tokenCount?: number;
    source: "session_history";
    nodeId: string;
    index: number;
    /** èŠ‚ç‚¹æ‰€ä½¿ç”¨çš„æ™ºèƒ½ä½“åç§°ï¼ˆå¿«ç…§ï¼‰ */
    agentName?: string;
    /** èŠ‚ç‚¹æ‰€ä½¿ç”¨çš„æ™ºèƒ½ä½“å›¾æ ‡ï¼ˆå¿«ç…§ï¼‰ */
    agentIcon?: string;
  }>;
  /** æœ€ç»ˆæ„å»ºçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äºåŸå§‹è¯·æ±‚å±•ç¤ºï¼‰ */
  finalMessages: Array<{
    role: "system" | "user" | "assistant";
    content: string | LlmMessageContent[];
  }>;
  /** ç»Ÿè®¡ä¿¡æ¯ */
  statistics: {
    totalCharCount: number;
    systemPromptCharCount: number;
    presetMessagesCharCount: number;
    chatHistoryCharCount: number;
    messageCount: number;
    totalTokenCount?: number;
    systemPromptTokenCount?: number;
    presetMessagesTokenCount?: number;
    chatHistoryTokenCount?: number;
    isEstimated?: boolean;
    tokenizerName?: string;
  };
  /** Agent ä¿¡æ¯ */
  agentInfo: {
    id: string;
    name?: string;
    icon?: string;
    profileId: string;
    modelId: string;
  };
}

export function useChatContextBuilder() {
  const { assetToMessageContent } = useChatAssetProcessor();
  const { processMacros, processMacrosBatch } = useMacroProcessor();

  /**
   * åº”ç”¨ä¸Šä¸‹æ–‡ Token é™åˆ¶ï¼Œæˆªæ–­ä¼šè¯å†å²
   */
  const applyContextLimit = async (
    sessionContext: Array<{ role: "user" | "assistant"; content: string | LlmMessageContent[] }>,
    systemMessages: Array<{ role: "system"; content: string }>,
    presetMessages: Array<{ role: "user" | "assistant"; content: string | LlmMessageContent[] }>,
    contextManagement: { enabled: boolean; maxContextTokens: number; retainedCharacters: number },
    modelId: string
  ): Promise<Array<{ role: "user" | "assistant"; content: string | LlmMessageContent[] }>> => {
    const { maxContextTokens, retainedCharacters } = contextManagement;

    // è®¡ç®—ç³»ç»Ÿæ¶ˆæ¯çš„ token æ•°
    let systemPromptTokens = 0;
    for (const sysMsg of systemMessages) {
      try {
        const result = await tokenCalculatorService.calculateTokens(sysMsg.content, modelId);
        systemPromptTokens += result.count;
      } catch (error) {
        logger.warn("è®¡ç®—ç³»ç»Ÿæ¶ˆæ¯ token å¤±è´¥", {
          error: error instanceof Error ? error.message : String(error),
        });
      }
    }

    // è®¡ç®—é¢„è®¾æ¶ˆæ¯çš„ token æ•°ï¼ˆå¹¶è¡Œè®¡ç®—ï¼‰
    const presetTokenResults = await Promise.all(
      presetMessages.map(async (msg) => {
        try {
          const content =
            typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content);
          const result = await tokenCalculatorService.calculateTokens(content, modelId);
          return result.count;
        } catch (error) {
          logger.warn("è®¡ç®—é¢„è®¾æ¶ˆæ¯ token å¤±è´¥", {
            error: error instanceof Error ? error.message : String(error),
          });
          return 0;
        }
      })
    );
    const presetMessagesTokens = presetTokenResults.reduce((sum, count) => sum + count, 0);

    // è®¡ç®—å¯ç”¨äºä¼šè¯å†å²çš„ token æ•°é‡
    const availableTokens = maxContextTokens - systemPromptTokens - presetMessagesTokens;

    logger.info("ğŸ“Š ä¸Šä¸‹æ–‡é™åˆ¶æ£€æŸ¥", {
      maxContextTokens,
      systemPromptTokens,
      presetMessagesTokens,
      availableTokens,
      sessionMessageCount: sessionContext.length,
    }, true);

    if (availableTokens <= 0) {
      logger.warn("âš ï¸ é¢„è®¾æ¶ˆæ¯å’Œç³»ç»Ÿæç¤ºå·²è¶…å‡ºæœ€å¤§ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œä¼šè¯å†å²å°†è¢«å®Œå…¨æˆªæ–­", {
        systemPromptTokens,
        presetMessagesTokens,
        maxContextTokens,
      });
      return [];
    }

    // è®¡ç®—æ¯æ¡ä¼šè¯æ¶ˆæ¯çš„ token æ•°
    const messagesWithTokens = await Promise.all(
      sessionContext.map(async (msg, index) => {
        let tokenCount = 0;
        try {
          let content = "";
          if (typeof msg.content === "string") {
            content = msg.content;
          } else {
            // å¯¹äºå¤šæ¨¡æ€å†…å®¹ï¼Œåªè®¡ç®—æ–‡æœ¬éƒ¨åˆ†çš„ token
            for (const part of msg.content) {
              if (part.type === "text" && part.text) {
                content += part.text;
              }
            }
          }
          const result = await tokenCalculatorService.calculateTokens(content, modelId);
          tokenCount = result.count;
        } catch (error) {
          logger.warn("è®¡ç®—æ¶ˆæ¯ token å¤±è´¥", {
            index,
            error: error instanceof Error ? error.message : String(error),
          });
        }
        return {
          ...msg,
          tokenCount,
          index,
        };
      })
    );

    // ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹ä¿ç•™ï¼Œç›´åˆ°è¾¾åˆ° token é™åˆ¶
    let totalTokens = 0;
    const keptIndices = new Set<number>();
    const truncatedIndices = new Set<number>();

    // ä»åå¾€å‰ï¼ˆæœ€æ–°åˆ°æœ€æ—§ï¼‰éå†æ¶ˆæ¯
    for (let i = messagesWithTokens.length - 1; i >= 0; i--) {
      const msg = messagesWithTokens[i];
      if (totalTokens + msg.tokenCount <= availableTokens) {
        totalTokens += msg.tokenCount;
        keptIndices.add(i);
      } else {
        truncatedIndices.add(i);
      }
    }

    logger.info("âœ‚ï¸ ä¸Šä¸‹æ–‡æˆªæ–­ç»“æœ", {
      totalMessages: sessionContext.length,
      keptMessages: keptIndices.size,
      truncatedMessages: truncatedIndices.size,
      usedTokens: totalTokens,
      availableTokens,
    }, true);

    // æ„å»ºç»“æœï¼šå¯¹äºè¢«æˆªæ–­çš„æ¶ˆæ¯ï¼Œä¿ç•™æŒ‡å®šçš„å­—ç¬¦æ•°
    const result = messagesWithTokens.map((msg, index) => {
      if (keptIndices.has(index)) {
        // å®Œæ•´ä¿ç•™
        return {
          role: msg.role,
          content: msg.content,
        };
      } else {
        // æˆªæ–­å¤„ç†
        let truncatedContent: string | LlmMessageContent[];

        if (typeof msg.content === "string") {
          // çº¯æ–‡æœ¬æ¶ˆæ¯
          if (retainedCharacters > 0 && msg.content.length > retainedCharacters) {
            truncatedContent = msg.content.substring(0, retainedCharacters) + "...[å·²æˆªæ–­]";
          } else if (retainedCharacters > 0) {
            truncatedContent = msg.content + "[å·²æˆªæ–­]";
          } else {
            truncatedContent = "[æ¶ˆæ¯å·²æˆªæ–­]";
          }
        } else {
          // å¤šæ¨¡æ€æ¶ˆæ¯ï¼šä¿ç•™ç»“æ„ï¼Œä½†æˆªæ–­æ–‡æœ¬éƒ¨åˆ†
          truncatedContent = msg.content.map((part) => {
            if (part.type === "text" && part.text) {
              let text = part.text;
              if (retainedCharacters > 0 && text.length > retainedCharacters) {
                text = text.substring(0, retainedCharacters) + "...[å·²æˆªæ–­]";
              } else if (retainedCharacters > 0) {
                text = text + "[å·²æˆªæ–­]";
              } else {
                text = "[æ¶ˆæ¯å·²æˆªæ–­]";
              }
              return { ...part, text };
            }
            return part;
          });
        }

        logger.debug("æˆªæ–­æ¶ˆæ¯", {
          index,
          role: msg.role,
          originalLength: typeof msg.content === "string" ? msg.content.length : "multimodal",
          retainedCharacters,
        });

        return {
          role: msg.role,
          content: truncatedContent,
        };
      }
    });

    return result;
  };

  /**
   * æ„å»º LLM ä¸Šä¸‹æ–‡
   * ä»æ´»åŠ¨è·¯å¾„å’Œæ™ºèƒ½ä½“é…ç½®ä¸­æå–ç³»ç»Ÿæç¤ºã€å¯¹è¯å†å²å’Œå½“å‰æ¶ˆæ¯
   * @param session å½“å‰ä¼šè¯ï¼ˆç”¨äºå®ä¸Šä¸‹æ–‡ï¼‰
   * @param effectiveUserProfile å½“å‰ç”Ÿæ•ˆçš„ç”¨æˆ·æ¡£æ¡ˆï¼ˆå¯é€‰ï¼‰
   * @param capabilities æ¨¡å‹èƒ½åŠ›ï¼ˆå¯é€‰ï¼Œç”¨äºæ™ºèƒ½é™„ä»¶å¤„ç†ï¼‰
   */
  const buildLlmContext = async (
    activePath: ChatMessageNode[],
    agentConfig: any,
    _currentUserMessage: string,
    session: ChatSession,
    effectiveUserProfile?: { id: string; name: string; content: string } | null,
    capabilities?: ModelCapabilities
  ): Promise<LlmContextData> => {
    // è¿‡æ»¤å‡ºæœ‰æ•ˆçš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæ’é™¤ç¦ç”¨èŠ‚ç‚¹å’Œç³»ç»ŸèŠ‚ç‚¹ï¼‰
    const llmContextPromises = activePath
      .filter((node) => node.isEnabled !== false)
      .filter((node) => node.role !== "system")
      .filter((node) => node.role === "user" || node.role === "assistant")
      .map(async (node) => {
        let content: string | LlmMessageContent[] = node.content;

        // å¦‚æœèŠ‚ç‚¹æœ‰é™„ä»¶ï¼Œæ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
        if (node.attachments && node.attachments.length > 0) {
          logger.info("ğŸ“ æ£€æµ‹åˆ°èŠ‚ç‚¹åŒ…å«é™„ä»¶", {
            nodeId: node.id,
            role: node.role,
            attachmentCount: node.attachments.length,
            attachments: node.attachments.map((a) => ({
              id: a.id,
              name: a.name,
              type: a.type,
              mimeType: a.mimeType,
              importStatus: a.importStatus,
            })),
          }, true);

          const messageContents: LlmMessageContent[] = [];

          // æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
          if (node.content && node.content.trim() !== "") {
            messageContents.push({
              type: "text",
              text: node.content,
            });
            logger.debug("æ·»åŠ æ–‡æœ¬å†…å®¹åˆ°æ¶ˆæ¯", {
              nodeId: node.id,
              textLength: node.content.length,
            });
          }

          // è½¬æ¢é™„ä»¶ï¼ˆä¼ é€’æ¨¡å‹èƒ½åŠ›ä¿¡æ¯ä»¥å®ç°æ™ºèƒ½å¤„ç†ï¼‰
          for (const asset of node.attachments) {
            logger.debug("å¼€å§‹è½¬æ¢é™„ä»¶", {
              nodeId: node.id,
              assetId: asset.id,
              assetName: asset.name,
              assetType: asset.type,
              importStatus: asset.importStatus,
              modelCapabilities: capabilities
                ? {
                    vision: capabilities.vision,
                    document: capabilities.document,
                  }
                : undefined,
            });

            const attachmentContent = await assetToMessageContent(asset, capabilities);
            if (attachmentContent) {
              messageContents.push(attachmentContent);
              logger.info("âœ… é™„ä»¶è½¬æ¢æˆåŠŸ", {
                nodeId: node.id,
                assetId: asset.id,
                assetName: asset.name,
                contentType: attachmentContent.type,
              });
            } else {
              logger.warn("âš ï¸ é™„ä»¶è½¬æ¢å¤±è´¥æˆ–è·³è¿‡", {
                nodeId: node.id,
                assetId: asset.id,
                assetName: asset.name,
                assetType: asset.type,
              });
            }
          }

          content = messageContents;

          logger.info("ğŸ“¦ å¤šæ¨¡æ€æ¶ˆæ¯æ„å»ºå®Œæˆ", {
            nodeId: node.id,
            role: node.role,
            originalAttachmentCount: node.attachments.length,
            finalMessagePartsCount: messageContents.length,
            hasTextContent: node.content && node.content.trim() !== "",
          }, true);
        } else {
          logger.debug("èŠ‚ç‚¹æ— é™„ä»¶ï¼Œä½¿ç”¨çº¯æ–‡æœ¬å†…å®¹", {
            nodeId: node.id,
            role: node.role,
            contentLength: node.content.length,
          });
        }

        return {
          role: node.role as "user" | "assistant",
          content,
        };
      });

    const llmContext = await Promise.all(llmContextPromises);

    // å¤„ç†é¢„è®¾æ¶ˆæ¯
    const presetMessages = agentConfig.presetMessages || [];
    const enabledPresets = presetMessages.filter((msg: any) => msg.isEnabled !== false);

    // è·å–å½“å‰æ™ºèƒ½ä½“ä¿¡æ¯ï¼ˆç”¨äºå®ä¸Šä¸‹æ–‡ï¼‰
    const agentStoreInstance = useAgentStore();
    const currentAgent = agentStoreInstance.getAgentById(
      agentStoreInstance.currentAgentId || ''
    );

    // æ„å»º system æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…æ‹¬ç”¨æˆ·æ¡£æ¡ˆï¼‰
    const systemMessagesList: Array<{
      role: "system";
      content: string;
    }> = [];

    // æŸ¥æ‰¾ç”¨æˆ·æ¡£æ¡ˆå ä½ç¬¦
    const userProfilePlaceholderIndex = enabledPresets.findIndex(
      (msg: any) => msg.type === "user_profile"
    );

    // æ”¶é›†æ‰€æœ‰ system æ¶ˆæ¯
    for (let i = 0; i < enabledPresets.length; i++) {
      const msg = enabledPresets[i];

      // è·³è¿‡ç”¨æˆ·æ¡£æ¡ˆå ä½ç¬¦æœ¬èº«
      if (msg.type === "user_profile") {
        // å¦‚æœæœ‰ç”¨æˆ·æ¡£æ¡ˆï¼Œåœ¨æ­¤ä½ç½®æ’å…¥ï¼ˆå¤„ç†å®ï¼‰
        if (effectiveUserProfile) {
          const userProfilePrompt = `# ç”¨æˆ·æ¡£æ¡ˆ\n${effectiveUserProfile.content}`;
          const processedUserProfile = await processMacros(userProfilePrompt, {
            session,
            agent: currentAgent ?? undefined,
            userProfile: effectiveUserProfile as any,
          });

          systemMessagesList.push({
            role: "system",
            content: processedUserProfile,
          });

          logger.debug("åœ¨å ä½ç¬¦ä½ç½®æ³¨å…¥ç”¨æˆ·æ¡£æ¡ˆï¼ˆå·²å¤„ç†å®ï¼‰", {
            profileId: effectiveUserProfile.id,
            profileName: effectiveUserProfile.name,
            position: i,
            originalLength: userProfilePrompt.length,
            processedLength: processedUserProfile.length,
          });
        }
        continue;
      }

      // æ”¶é›†æ™®é€š system æ¶ˆæ¯ï¼ˆå¤„ç†å®ï¼‰
      if (msg.role === "system" && msg.type !== "chat_history") {
        const processedContent = await processMacros(msg.content, {
          session,
          agent: currentAgent ?? undefined,
          userProfile: effectiveUserProfile as any,
        });

        systemMessagesList.push({
          role: "system",
          content: processedContent,
        });
      }
    }

    // å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¡£æ¡ˆå ä½ç¬¦ï¼Œä½†æœ‰ç”¨æˆ·æ¡£æ¡ˆï¼Œåˆ™è¿½åŠ åˆ° system æ¶ˆæ¯æœ«å°¾ï¼ˆå¤„ç†å®ï¼‰
    if (userProfilePlaceholderIndex === -1 && effectiveUserProfile) {
      const userProfilePrompt = `# ç”¨æˆ·æ¡£æ¡ˆ\n${effectiveUserProfile.content}`;
      const processedUserProfile = await processMacros(userProfilePrompt, {
        session,
        agent: currentAgent ?? undefined,
        userProfile: effectiveUserProfile as any,
      });

      systemMessagesList.push({
        role: "system",
        content: processedUserProfile,
      });

      logger.debug("è¿½åŠ ç”¨æˆ·æ¡£æ¡ˆåˆ° system æ¶ˆæ¯æœ«å°¾ï¼ˆæ— å ä½ç¬¦ï¼Œå·²å¤„ç†å®ï¼‰", {
        profileId: effectiveUserProfile.id,
        profileName: effectiveUserProfile.name,
        originalLength: userProfilePrompt.length,
        processedLength: processedUserProfile.length,
      });
    }

    // ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆå®Œæ•´å†å²ï¼Œä¸å†å•ç‹¬å¤„ç†æœ€åä¸€æ¡ï¼‰
    let sessionContext = llmContext;

    // æŸ¥æ‰¾å†å²æ¶ˆæ¯å ä½ç¬¦
    const chatHistoryPlaceholderIndex = enabledPresets.findIndex(
      (msg: any) => msg.type === "chat_history"
    );

    // å‡†å¤‡é¢„è®¾å¯¹è¯ï¼ˆç”¨äº token è®¡ç®—ï¼Œä¸åŒ…æ‹¬ systemï¼‰
    // éœ€è¦å¤„ç†å®
    const presetConversationRaw = enabledPresets.filter(
      (msg: any) =>
        (msg.role === "user" || msg.role === "assistant") && msg.type !== "user_profile"
    );

    const presetConversationContents = await processMacrosBatch(
      presetConversationRaw.map((msg: any) => msg.content),
      {
        session,
        agent: currentAgent ?? undefined,
        userProfile: effectiveUserProfile as any,
      }
    );

    const presetConversation: Array<{
      role: "user" | "assistant";
      content: string | LlmMessageContent[];
    }> = presetConversationRaw.map((msg: any, index: number) => ({
      role: msg.role as "user" | "assistant",
      content: presetConversationContents[index],
    }));

    // åº”ç”¨ä¸Šä¸‹æ–‡ Token é™åˆ¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    // æ³¨æ„ï¼šä¸Šä¸‹æ–‡é™åˆ¶ç›®å‰ä¸è€ƒè™‘ system æ¶ˆæ¯ï¼Œåªæˆªæ–­ä¼šè¯å†å²
    if (
      agentConfig.parameters.contextManagement?.enabled &&
      agentConfig.parameters.contextManagement.maxContextTokens > 0
    ) {
      logger.info("ğŸ” å¼€å§‹åº”ç”¨ä¸Šä¸‹æ–‡é™åˆ¶", {
        enabled: agentConfig.parameters.contextManagement.enabled,
        maxContextTokens: agentConfig.parameters.contextManagement.maxContextTokens,
        retainedCharacters: agentConfig.parameters.contextManagement.retainedCharacters,
      });

      sessionContext = await applyContextLimit(
        sessionContext,
        systemMessagesList,
        presetConversation,
        agentConfig.parameters.contextManagement,
        agentConfig.modelId
      );
    }

    // æ„å»ºæœ€ç»ˆçš„ user/assistant æ¶ˆæ¯åˆ—è¡¨
    let userAssistantMessages: Array<{
      role: "user" | "assistant";
      content: string | LlmMessageContent[];
    }>;

    if (chatHistoryPlaceholderIndex !== -1) {
      // å¦‚æœæ‰¾åˆ°å ä½ç¬¦ï¼Œå°†ä¼šè¯ä¸Šä¸‹æ–‡æ’å…¥åˆ°å ä½ç¬¦ä½ç½®
      // å¤„ç†å ä½ç¬¦å‰åçš„é¢„è®¾æ¶ˆæ¯çš„å®
      const presetsBeforeRaw = enabledPresets
        .slice(0, chatHistoryPlaceholderIndex)
        .filter(
          (msg: any) =>
            (msg.role === "user" || msg.role === "assistant") && msg.type !== "user_profile"
        );

      const presetsAfterRaw = enabledPresets
        .slice(chatHistoryPlaceholderIndex + 1)
        .filter(
          (msg: any) =>
            (msg.role === "user" || msg.role === "assistant") && msg.type !== "user_profile"
        );

      const presetsBeforeContents = await processMacrosBatch(
        presetsBeforeRaw.map((msg: any) => msg.content),
        {
          session,
          agent: currentAgent ?? undefined,
          userProfile: effectiveUserProfile as any,
        }
      );

      const presetsAfterContents = await processMacrosBatch(
        presetsAfterRaw.map((msg: any) => msg.content),
        {
          session,
          agent: currentAgent ?? undefined,
          userProfile: effectiveUserProfile as any,
        }
      );

      const presetsBeforePlaceholder: Array<{
        role: "user" | "assistant";
        content: string | LlmMessageContent[];
      }> = presetsBeforeRaw.map((msg: any, index: number) => ({
        role: msg.role as "user" | "assistant",
        content: presetsBeforeContents[index],
      }));

      const presetsAfterPlaceholder: Array<{
        role: "user" | "assistant";
        content: string | LlmMessageContent[];
      }> = presetsAfterRaw.map((msg: any, index: number) => ({
        role: msg.role as "user" | "assistant",
        content: presetsAfterContents[index],
      }));

      userAssistantMessages = [
        ...presetsBeforePlaceholder,
        ...sessionContext,
        ...presetsAfterPlaceholder,
      ];

      logger.debug("ä½¿ç”¨å†å²æ¶ˆæ¯å ä½ç¬¦æ„å»ºä¸Šä¸‹æ–‡", {
        presetsBeforeCount: presetsBeforePlaceholder.length,
        sessionContextCount: sessionContext.length,
        presetsAfterCount: presetsAfterPlaceholder.length,
        totalUserAssistantMessages: userAssistantMessages.length,
      }, true);
    } else {
      // å¦‚æœæ²¡æœ‰å ä½ç¬¦ï¼ŒæŒ‰åŸæ¥çš„é€»è¾‘ï¼šé¢„è®¾æ¶ˆæ¯åœ¨å‰ï¼Œä¼šè¯ä¸Šä¸‹æ–‡åœ¨å
      userAssistantMessages = [...presetConversation, ...sessionContext];
    }

    // åˆå¹¶ system æ¶ˆæ¯å’Œ user/assistant æ¶ˆæ¯ï¼Œæ„å»ºç»Ÿä¸€çš„æ¶ˆæ¯åˆ—è¡¨
    const messages: Array<{
      role: "system" | "user" | "assistant";
      content: string | LlmMessageContent[];
    }> = [...systemMessagesList, ...userAssistantMessages];

    // è¯¦ç»†çš„ debug æ—¥å¿—ï¼Œå±•ç¤ºæœ€ç»ˆæ„å»ºçš„æ¶ˆæ¯
    logger.debug("ğŸ” æ„å»º LLM ä¸Šä¸‹æ–‡å®Œæˆ", {
      systemMessageCount: systemMessagesList.length,
      userAssistantMessageCount: userAssistantMessages.length,
      totalMessages: messages.length,
      messages: messages.map((msg, index) => ({
        index,
        role: msg.role,
        contentType: typeof msg.content,
        contentPreview:
          typeof msg.content === "string"
            ? msg.content.substring(0, 100) + (msg.content.length > 100 ? "..." : "")
            : `[${msg.content.length} parts]`,
        contentLength:
          typeof msg.content === "string"
            ? msg.content.length
            : msg.content.reduce(
                (sum, part) =>
                  sum +
                  (typeof part === "object" && "text" in part && part.text ? part.text.length : 0),
                0
              ),
      })),
    }, true);

    return { messages };
  };

  /**
   * è·å–æŒ‡å®šèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡é¢„è§ˆæ•°æ®ï¼ˆç”¨äºä¸Šä¸‹æ–‡åˆ†æå™¨ï¼‰
   * @param session å½“å‰ä¼šè¯
   * @param targetNodeId ç›®æ ‡èŠ‚ç‚¹ ID
   * @param agentStore Agent Store å®ä¾‹
   * @param nodeManager Node Manager å®ä¾‹
   * @param getProfileById LLM Profile è·å–å‡½æ•°
   * @param applyProcessingPipeline åå¤„ç†ç®¡é“åº”ç”¨å‡½æ•°
   * @param agentId ä½¿ç”¨çš„ Agent IDï¼ˆå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™ä»èŠ‚ç‚¹æ¨æ–­ï¼‰
   * @returns è¯¦ç»†çš„ä¸Šä¸‹æ–‡åˆ†ææ•°æ®ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å› null
   */
  const getLlmContextForPreview = async (
    session: ChatSession,
    targetNodeId: string,
    agentStore: any,
    nodeManager: any,
    getProfileById: any,
    applyProcessingPipeline?: (
      messages: ProcessableMessage[],
      rules: ContextPostProcessRule[]
    ) => ProcessableMessage[],
    agentId?: string
  ): Promise<ContextPreviewData | null> => {
    const sanitizeForCharCount = (text: string): string => {
      if (!text) return "";
      const base64ImageRegex = /!\[.*?\]\(data:image\/[a-zA-Z0-9-+.]+;base64,.*?\)/g;
      return text.replace(base64ImageRegex, "[IMAGE]");
    };

    // è·å–ç›®æ ‡èŠ‚ç‚¹
    const targetNode = session.nodes[targetNodeId];
    if (!targetNode) {
      logger.warn("è·å–ä¸Šä¸‹æ–‡é¢„è§ˆå¤±è´¥ï¼šèŠ‚ç‚¹ä¸å­˜åœ¨", { targetNodeId });
      return null;
    }

    // è·å–åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„
    const nodePath = nodeManager.getNodePath(session, targetNodeId);

    // ç¡®å®šä½¿ç”¨çš„ Agent ID
    let effectiveAgentId: string | null;
    if (agentId) {
      // å¦‚æœæä¾›äº† agentId å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨
      effectiveAgentId = agentId;
      logger.debug("ä½¿ç”¨æä¾›çš„ Agent ID", { agentId });
    } else {
      // å¦åˆ™ä»èŠ‚ç‚¹ metadata ä¸­æ¨æ–­
      effectiveAgentId = targetNode.metadata?.agentId || agentStore.currentAgentId;
      // å¦‚æœç›®æ ‡èŠ‚ç‚¹æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œå°è¯•ä»å…¶å­èŠ‚ç‚¹ï¼ˆåŠ©æ‰‹æ¶ˆæ¯ï¼‰ä¸­è·å– agentId
      if (!effectiveAgentId && targetNode.role === "user" && targetNode.childrenIds.length > 0) {
        const firstChild = session.nodes[targetNode.childrenIds[0]];
        effectiveAgentId = firstChild?.metadata?.agentId || null;
      }
      logger.debug("ä»èŠ‚ç‚¹æ¨æ–­ Agent ID", {
        targetNodeId,
        inferredAgentId: effectiveAgentId,
        source: targetNode.metadata?.agentId ? 'node_metadata' : 'current_agent'
      });
    }

    // å¦‚æœæ²¡æœ‰ Agentï¼Œè­¦å‘Šå¹¶ç»§ç»­å¤„ç†ï¼ˆåªè®¡ç®—ä¼šè¯å†å²ï¼‰
    if (!effectiveAgentId) {
      logger.warn("âš ï¸ æ— æ³•ç¡®å®š Agentï¼Œå°†åªè®¡ç®—ä¼šè¯å†å²ï¼ˆä¸åŒ…å«æ™ºèƒ½ä½“é¢„è®¾ï¼‰", {
        targetNodeId,
        providedAgentId: agentId
      });
    }

    // å°è¯•è·å– Agent é…ç½®
    let agentConfig: any = null;
    let agent: any = null;
    let model: any = null;

    if (effectiveAgentId) {
      agentConfig = agentStore.getAgentConfig(effectiveAgentId, {
        parameterOverrides: session.parameterOverrides,
      });

      if (!agentConfig) {
        logger.warn("âš ï¸ æ— æ³•è·å– Agent é…ç½®ï¼Œå°†åªè®¡ç®—ä¼šè¯å†å²", { agentId: effectiveAgentId });
      } else {
        agent = agentStore.getAgentById(effectiveAgentId);
        const profile = getProfileById(agentConfig.profileId);
        model = profile?.models.find((m: any) => m.id === agentConfig.modelId);
      }
    }

    // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    let messages: Array<{
      role: "system" | "user" | "assistant";
      content: string | LlmMessageContent[];
    }> = [];

    if (agentConfig) {
      // æœ‰ Agent é…ç½®æ—¶ï¼Œä½¿ç”¨å®Œæ•´çš„ä¸Šä¸‹æ–‡æ„å»º
      const contextData = await buildLlmContext(
        nodePath,
        agentConfig,
        "", // currentUserMessage å‚æ•°å·²ä¸ä½¿ç”¨
        session
      );
      messages = contextData.messages;

      // åº”ç”¨ä¸Šä¸‹æ–‡åå¤„ç†ç®¡é“ï¼ˆç”¨äºé¢„è§ˆçœŸå®å‘é€çš„å†…å®¹ï¼‰
      const modelDefaultRules = model?.defaultPostProcessingRules || [];
      const agentRules = agentConfig.parameters.contextPostProcessing?.rules || [];

      const modelRulesObjects = modelDefaultRules.map((type: string) => ({ type, enabled: true }));
      const agentRuleTypes = new Set(agentRules.map((r: any) => r.type));
      const mergedRules = [
        ...agentRules,
        ...modelRulesObjects.filter((r: any) => !agentRuleTypes.has(r.type)),
      ];

      if (mergedRules.length > 0 && applyProcessingPipeline) {
        messages = applyProcessingPipeline(messages, mergedRules);
        logger.debug("åº”ç”¨åå¤„ç†è§„åˆ™ï¼ˆé¢„è§ˆï¼‰", { mergedRulesCount: mergedRules.length }, true);
      }
    } else {
      // æ²¡æœ‰ Agent é…ç½®æ—¶ï¼Œåªæ„å»ºåŒ…å«é™„ä»¶çš„ä¼šè¯å†å²æ¶ˆæ¯
      logger.info("ğŸ“ ä»…æ„å»ºä¼šè¯å†å²æ¶ˆæ¯ï¼ˆæ—  Agent é¢„è®¾ï¼‰");
      messages = await Promise.all(nodePath
        .filter((node: ChatMessageNode) => node.isEnabled !== false && (node.role === 'user' || node.role === 'assistant'))
        .map(async (node: ChatMessageNode) => {
          let content: string | LlmMessageContent[] = node.content;
          if (node.attachments && node.attachments.length > 0) {
            const messageContents: LlmMessageContent[] = [];
            if (node.content && node.content.trim() !== "") {
              messageContents.push({ type: "text", text: node.content });
            }
            for (const asset of node.attachments) {
              // åœ¨æ²¡æœ‰æ¨¡å‹ä¿¡æ¯æ—¶ï¼Œcapabilities ä¸º undefinedï¼ŒassetToMessageContent ä¼šåšé™çº§å¤„ç†
              const attachmentContent = await assetToMessageContent(asset, undefined);
              if (attachmentContent) messageContents.push(attachmentContent);
            }
            content = messageContents;
          }
          return { role: node.role as "user" | "assistant", content };
        }));
    }

    // è®¡ç®— Token æ•°
    let systemPromptTokenCount = 0;
    let presetMessagesTokenCount = 0;
    let chatHistoryTokenCount = 0;
    let isEstimated = false;
    let tokenizerName = "";

    // æå–ç³»ç»Ÿæ¶ˆæ¯éƒ¨åˆ†ï¼ˆä»…å½“æœ‰ Agent é…ç½®æ—¶ï¼‰
    let systemPromptData: ContextPreviewData["systemPrompt"];
    if (agentConfig) {
      const systemMessages = messages.filter((m) => m.role === "system");
      if (systemMessages.length > 0) {
        const combinedSystemContent = systemMessages.map((m) => typeof m.content === "string" ? m.content : JSON.stringify(m.content)).join("\n\n");
        const sanitizedSystemContent = sanitizeForCharCount(combinedSystemContent);
        try {
          const tokenResult = await tokenCalculatorService.calculateTokens(combinedSystemContent, agentConfig.modelId);
          systemPromptTokenCount = tokenResult.count;
          isEstimated = tokenResult.isEstimated ?? false;
          tokenizerName = tokenResult.tokenizerName;
          systemPromptData = { content: combinedSystemContent, charCount: sanitizedSystemContent.length, tokenCount: tokenResult.count, source: "agent_preset" };
        } catch (error) {
          logger.warn("è®¡ç®—ç³»ç»Ÿæ¶ˆæ¯ token å¤±è´¥", { error: error instanceof Error ? error.message : String(error) });
          systemPromptData = { content: combinedSystemContent, charCount: sanitizedSystemContent.length, source: "agent_preset" };
        }
      }
    }

    // æå–é¢„è®¾å¯¹è¯éƒ¨åˆ†ï¼ˆä»…å½“æœ‰ Agent é…ç½®æ—¶ï¼‰
    // æ³¨æ„ï¼šé¢„è®¾æ¶ˆæ¯çš„å†…å®¹å·²ç»åœ¨ buildLlmContext ä¸­å¤„ç†è¿‡å®ï¼Œè¿™é‡Œä» finalMessages ä¸­æå–
    const presetMessagesData: ContextPreviewData["presetMessages"] = agentConfig ? await Promise.all(
      (agentConfig.presetMessages || []).filter((msg: any) => msg.isEnabled !== false && msg.role !== "system" && msg.type !== "chat_history")
        .map(async (msg: any, index: number) => {
          // ä» finalMessages ä¸­æ‰¾åˆ°å¯¹åº”çš„æ¶ˆæ¯ï¼ˆå·²å¤„ç†å®ï¼‰
          // é¢„è®¾æ¶ˆæ¯åœ¨ finalMessages ä¸­ç´§è·Ÿåœ¨ system æ¶ˆæ¯ä¹‹å
          const systemMessageCount = messages.filter((m) => m.role === "system").length;
          const messageInFinal = messages[systemMessageCount + index];
          const content = messageInFinal
            ? (typeof messageInFinal.content === "string" ? messageInFinal.content : JSON.stringify(messageInFinal.content))
            : (typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content));
          
          const sanitizedContent = sanitizeForCharCount(content);
          let tokenCount: number | undefined;
          try {
            const tokenResult = await tokenCalculatorService.calculateTokens(content, agentConfig.modelId);
            tokenCount = tokenResult.count;
            presetMessagesTokenCount += tokenResult.count;
            if (tokenResult.isEstimated) isEstimated = true;
          } catch (error) {
            logger.warn("è®¡ç®—é¢„è®¾æ¶ˆæ¯ token å¤±è´¥", { index, error: error instanceof Error ? error.message : String(error) });
          }
          return { role: msg.role, content, charCount: sanitizedContent.length, tokenCount, source: "agent_preset", index };
        })
    ) : [];

    // ä»èŠ‚ç‚¹è·¯å¾„ä¸­æå–ä¼šè¯å†å²
    const chatHistoryData = await Promise.all(
      nodePath
        .filter((node: ChatMessageNode) => node.isEnabled !== false && (node.role === 'user' || node.role === 'assistant'))
        .map(async (node: ChatMessageNode, index: number) => {
          let content = typeof node.content === "string" ? node.content : JSON.stringify(node.content);
          if (node.role === "user" && node.attachments && node.attachments.length > 0) {
            const { getTextAttachmentsContent } = useChatAssetProcessor();
            const textAttachmentsContent = await getTextAttachmentsContent(node.attachments);
            if (textAttachmentsContent) content = `${content}\n\n${textAttachmentsContent}`;
          }
          
          let tokenCount: number | undefined;
          const sanitizedContent = sanitizeForCharCount(content);
          if (agentConfig) { // åªæœ‰åœ¨æœ‰ Agent é…ç½®æ—¶æ‰è®¡ç®— token
            try {
              const tokenResult = (node.role === "user" && node.attachments && node.attachments.length > 0)
                ? await tokenCalculatorService.calculateMessageTokens(content, agentConfig.modelId, node.attachments)
                : await tokenCalculatorService.calculateTokens(content, agentConfig.modelId);
              tokenCount = tokenResult.count;
              chatHistoryTokenCount += tokenResult.count;
              if (tokenResult.isEstimated) isEstimated = true;
            } catch (error) {
              logger.warn("è®¡ç®—ä¼šè¯å†å² token å¤±è´¥", { nodeId: node.id, index, error: error instanceof Error ? error.message : String(error) });
            }
          }
          return { role: node.role, content, charCount: sanitizedContent.length, tokenCount, source: "session_history", nodeId: node.id, index };
        })
    );

    // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    const systemPromptCharCount = systemPromptData?.charCount || 0;
    const presetMessagesCharCount = presetMessagesData.reduce((sum, msg) => sum + msg.charCount, 0);
    const chatHistoryCharCount = chatHistoryData.reduce((sum, msg) => sum + msg.charCount, 0);
    const totalCharCount = systemPromptCharCount + presetMessagesCharCount + chatHistoryCharCount;
    const totalTokenCount = systemPromptTokenCount + presetMessagesTokenCount + chatHistoryTokenCount;

    const result: ContextPreviewData = {
      systemPrompt: systemPromptData,
      presetMessages: presetMessagesData,
      chatHistory: chatHistoryData,
      finalMessages: messages,
      statistics: {
        totalCharCount,
        systemPromptCharCount,
        presetMessagesCharCount,
        chatHistoryCharCount,
        messageCount: messages.length,
        totalTokenCount: agentConfig ? totalTokenCount : undefined,
        systemPromptTokenCount: agentConfig ? systemPromptTokenCount : undefined,
        presetMessagesTokenCount: agentConfig ? presetMessagesTokenCount : undefined,
        chatHistoryTokenCount: agentConfig ? chatHistoryTokenCount : undefined,
        isEstimated: agentConfig ? isEstimated : undefined,
        tokenizerName: agentConfig ? tokenizerName : undefined,
      },
      agentInfo: {
        id: effectiveAgentId ?? '',
        name: agent?.name,
        icon: agent?.icon,
        profileId: agentConfig?.profileId ?? '',
        modelId: agentConfig?.modelId ?? '',
      },
    };

    logger.debug("ğŸ” ç”Ÿæˆä¸Šä¸‹æ–‡é¢„è§ˆæ•°æ®", {
      targetNodeId,
      agentId: effectiveAgentId,
      providedAgentId: agentId,
      hasAgentConfig: !!agentConfig,
      totalCharCount,
      totalTokenCount: agentConfig ? totalTokenCount : 'N/A (æ—  Agent)',
      messageCount: messages.length,
    }, true);

    return result;
  };

  return {
    buildLlmContext,
    applyContextLimit,
    getLlmContextForPreview,
  };
}
